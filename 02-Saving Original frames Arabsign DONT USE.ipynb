{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT SAVING FRAMES, JUST PUT IN LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_frame(input_video_path):\n",
    "    frames_list = []\n",
    "\n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Loop through each frame and save as an image\n",
    "    for frame_number in range(frame_count):\n",
    "        # Read the next frame\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Save the frame as an image\n",
    "        #image_path = os.path.join(output_folder, f\"frame_{frame_number:04d}.png\")\n",
    "        #cv2.imwrite(image_path, frame)\n",
    "        frames_list.append(frame)\n",
    "\n",
    "    # Release the video capture object\n",
    "    video_capture.release()\n",
    "    return frames_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COVERT LIST TO SAVED GRAYSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertListToGrayScale(videoFrames, output_directory): # directory_path, \n",
    "    # List all frames of the video in the folder with the specified directory_path\n",
    "    #videoFrames = [frame for frame in os.listdir(directory_path)]       # name of file\n",
    "\n",
    "    # List all \n",
    "    #grayImagesList = [] \n",
    "    for frame_number, frame in enumerate(videoFrames):\n",
    "        #frame_path = os.path.join(directory_path, frame)\n",
    "        #grayImage = cv2.imread(frame, cv2.IMREAD_GRAYSCALE)\n",
    "        grayImage = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        #grayImagesList.append(grayImage.astype(np.int16))\n",
    "        \n",
    "        # Save the grayscale image to a directory\n",
    "        output_path = os.path.join(output_directory, f\"gray_frame_{frame_number:04d}.jpg\")\n",
    "        cv2.imwrite(output_path, grayImage)\n",
    "        \n",
    "    logging.info(f\"video images '{output_directory[-10:]}' converted to grayscale and saved in '{output_directory}'\")\n",
    "\n",
    "    #return grayImagesList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN FOR LIST FRAMES AND SAVED GRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"C:\\Users\\zaher.salman\\Desktop\\LINA JAN 24\\Senior II\\ArabSign Dataset\"      # path to whole Dataset Folder\n",
    "folders = [participant for participant in os.listdir(dataset_path)]                         # each 6 participents\n",
    "for participant in folders:                                                 \n",
    "    train_path = os.path.join(dataset_path, participant, 'train')                           # directly open the train for each participant\n",
    "    for sentence_folder in os.listdir(train_path):\n",
    "        sentence_path = os.path.join(train_path, sentence_folder)                           # get the path to a folder for one sentence\n",
    "        for video in os.listdir(sentence_path):                                             # for every training video in that sentence folder\n",
    "            input_video_path = os.path.join(sentence_path, video)                           # input is the path of the individual video\n",
    "            video_name = os.path.splitext(os.path.basename(video))[0]                       # using the same name as the video (without .mp4 as the output folder name)\n",
    "            output_folder = os.path.join(sentence_path, video_name)                         # create the output folder to store the frames\n",
    "            if not os.path.exists(output_folder):\n",
    "                os.makedirs(output_folder)\n",
    "            list_of_frames = convert_to_frame(input_video_path)                              # saves all frames as images\n",
    "            convertListToGrayScale(list_of_frames, output_folder)\n",
    "        \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE FRAMES METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_frames_from_video(input_video_path, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Loop through each frame and save as an image\n",
    "    for frame_number in range(frame_count):\n",
    "        # Read the next frame\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Save the frame as an image\n",
    "        image_path = os.path.join(output_folder, f\"frame_{frame_number:04d}.png\")\n",
    "        cv2.imwrite(image_path, frame)\n",
    "\n",
    "    # Release the video capture object\n",
    "    video_capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING ALL FRAMES FOR WHOLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"C:\\Users\\zaher.salman\\Desktop\\LINA JAN 24\\Senior II\\ArabSign Dataset\"      # path to whole Dataset Folder\n",
    "folders = [participent for participent in os.listdir(dataset_path)]                         # each 6 participents\n",
    "for participent in folders:                                                 \n",
    "    train_path = os.path.join(dataset_path, participent, 'train')                           # directly open the train for each participent\n",
    "    for sentence_folder in os.listdir(train_path):\n",
    "        sentence_path = os.path.join(train_path, sentence_folder)                           # get the path to a folder for one sentence\n",
    "        for video in os.listdir(sentence_path):                                             # for every training video in that sentence folder\n",
    "            input_video_path = os.path.join(sentence_path, video)                           # input is the path of the individual video\n",
    "            video_name = os.path.splitext(os.path.basename(video))[0]                       # using the same name as the video (without .mp4 as the output folder name)\n",
    "            output_folder = os.path.join(sentence_path, video_name)                         # create the output folder to store the frames\n",
    "            os.makedirs(output_folder)\n",
    "            save_frames_from_video(input_video_path, output_folder)                         # saves all frames as images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVED FRAMES TO SAVE GRAY METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToGrayScale(directory_path, output_directory):\n",
    "    # List all frames of the video in the folder with the specified directory_path\n",
    "    videoFrames = [frame for frame in os.listdir(directory_path)]       # name of file\n",
    "\n",
    "    # List all \n",
    "    grayImagesList = [] \n",
    "    for frame in videoFrames:\n",
    "        frame_path = os.path.join(directory_path, frame)\n",
    "        grayImage = cv2.imread(frame_path, cv2.IMREAD_GRAYSCALE)\n",
    "        grayImagesList.append(grayImage.astype(np.int16))\n",
    "        \n",
    "        # Save the grayscale image to a directory\n",
    "        output_path = os.path.join(output_directory, f\"gray_{frame}\")\n",
    "        cv2.imwrite(output_path, grayImage)\n",
    "        \n",
    "    logging.info(f\"video images '{output_directory[-10:]}' converted to grayscale and saved in '{output_directory}'\")\n",
    "\n",
    "    return grayImagesList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USES SAVED IMAGES TO SAVED GRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"C:\\Users\\zaher.salman\\Desktop\\LINA JAN 24\\Senior II\\ArabSign Dataset\"\n",
    "folders = [participent for participent in os.listdir(dataset_path)]\n",
    "for participent in folders:\n",
    "    train_path = os.path.join(dataset_path, participent, 'train')\n",
    "    for sentence_folder in os.listdir(train_path):\n",
    "        sentence_path = os.path.join(train_path, sentence_folder)\n",
    "        frame_folders = [os.path.join(sentence_path, item) for item in os.listdir(sentence_path) if os.path.isdir(os.path.join(sentence_path, item))]\n",
    "        for folder in frame_folders:\n",
    "            convertToGrayScale(folder, folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
