{"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"nAoQVWH-E5mz"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24011,"status":"ok","timestamp":1714974558465,"user":{"displayName":"Mariam Binghalib","userId":"02449068467750039127"},"user_tz":-240},"id":"PZZDtvpynXrn","outputId":"fd6be4af-d3c5-491e-e6b5-0a07ec5f62a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"irPEskgkJube"},"outputs":[],"source":["import os\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.applications.inception_v3 import preprocess_input\n","from keras.layers import GlobalAveragePooling2D\n","from keras.models import Model\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sS7XDrku0Z2J"},"outputs":[],"source":["import random\n","random.seed(42)"]},{"cell_type":"markdown","source":["# Feature Extraction"],"metadata":{"id":"9OSTxyhGE8YZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XqKQq4OKVrg"},"outputs":[],"source":["def load_and_preprocess_image(image_path):\n","    img = load_img(image_path)\n","    img_array = img_to_array(img) # convert to numpy\n","    img_array = preprocess_input(img_array) # preprocesses for inceptionv3\n","    return img_array"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5535,"status":"ok","timestamp":1714974567369,"user":{"displayName":"Mariam Binghalib","userId":"02449068467750039127"},"user_tz":-240},"id":"BkIeDBodKami","outputId":"2edad6d5-7f41-4d4d-c471-dca90375f4e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 3s 0us/step\n"]}],"source":["inceptionv3_model = InceptionV3(include_top=False, weights='imagenet', input_shape=(299, 299, 3))\n","for layer in inceptionv3_model.layers:\n","    layer.trainable = False\n","\n","pooled_features = GlobalAveragePooling2D()(inceptionv3_model.output)\n","feature_extraction_model = Model(inputs=inceptionv3_model.input, outputs=pooled_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oPP8LqcKNO6w"},"outputs":[],"source":["training_dir = r'/content/drive/My Drive/Cropped Stacks Test'\n","# directory with /6 participants/train or test/50 sentences/sample folders/word folders/png images of stacks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dmsvcO9rKhp6"},"outputs":[],"source":["image_paths = []\n","labels = []\n","sentence_features = []\n","\n","participants = os.listdir(training_dir)\n","participants.sort()\n","folders = [participant for participant in participants]\n","for participant in folders:\n","    train_path = os.path.join(training_dir, participant, 'train') # change to 'test' when needed\n","    sentence_folders = os.listdir(train_path)\n","    sentence_folders.sort()\n","    for sentence_folder in sentence_folders:\n","        print(sentence_folder)\n","        sentence_path = os.path.join(train_path, sentence_folder)\n","        folders = os.listdir(sentence_path)\n","        folders.sort()\n","        for folder in folders:\n","            print(folder)\n","            folder_path = os.path.join(sentence_path, folder)\n","            current_sequence = []\n","            current_labels = []\n","            folder_paths = os.listdir(folder_path)\n","            folder_paths.sort()\n","            for word_folder in folder_paths:\n","                word_folder_path = os.path.join(folder_path, word_folder)\n","                words = os.listdir(word_folder_path)\n","                words.sort()\n","                for word in words:\n","                    if word.endswith(\".png\"):\n","                        image_path = os.path.join(word_folder_path, word)\n","                        label = int(os.path.splitext(word)[0])\n","                        image_array = load_and_preprocess_image(image_path)\n","                        img_array_batch = np.expand_dims(image_array, axis=0) # have to add batch size so it's (1, 299, 299, 3)\n","                        #print(img_array_batch)\n","                        features = feature_extraction_model.predict(img_array_batch)\n","                        current_sequence.append(features.flatten()) # to make a 1D array\n","                        current_labels.append(label)\n","            # pad to be 5 words\n","            if len(current_sequence) < 5:\n","              last_FV = current_sequence[-1]\n","              last_label = current_labels[-1]\n","              for i in range(5 - len(current_sequence)):\n","                current_sequence.append(last_FV)\n","                current_labels.append(last_label)\n","\n","            sentence_features.append(current_sequence)\n","            labels.append(current_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKOwppKmMI2a"},"outputs":[],"source":["np.save(r'/content/drive/My Drive/Model Files/X_test_cropped.npy', np.array(sentence_features))\n","np.save(r'/content/drive/My Drive/Model Files/y_test_cropped.npy', np.array(labels))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyOH/LT/Pew2usWAs3zCg04/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}